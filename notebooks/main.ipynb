{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1850fa",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 align=\"center\">Redes neuronales de Grafos Espacio Temporales</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4267d00",
   "metadata": {},
   "source": [
    "El objetivo de este cuaderno es desarrollar una Red Neuronal de Grafos Espaciotemporal (STGNN) para la predicción de tráfico utilizando <img src=\"https://raw.githubusercontent.com/TorchSpatiotemporal/tsl/main/docs/source/_static/img/tsl_logo.svg\" width=\"30px\" align=\"center\"/> [**Torch Spatiotemporal (tsl)**](https://torch-spatiotemporal.readthedocs.io/), una librería de Python diseñada específicamente para el procesamiento neuronal de datos espaciotemporales.\n",
    "\n",
    "Torch Spatiotemporal se basa en librerías populares del ecosistema científico de Python, como PyTorch, PyTorch Geometric (PyG) y PyTorch Lightning. Simplifica el flujo de trabajo para tareas que involucran series de tiempo con información relacional, incluyendo el preprocesamiento, el desarrollo de modelos y la evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a0134",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Inicio**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66896c",
   "metadata": {},
   "source": [
    "## Instalacion\n",
    "<hr>\n",
    "\n",
    "Lo primero que debemos realizar es configurar nuestro entorno de python que debe ser python >= 3.10\n",
    "\n",
    "Agregaremos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install initial dependencies\n",
    "%pip install -U pandas==2.0\n",
    "%pip install -U torch==2.3\n",
    "%pip install -U matplotlib\n",
    "%pip install -U tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed24ea",
   "metadata": {},
   "source": [
    "Se debe tener en cuenta que tsl debe instalarse en un entorno de Python que ya contenga Pytorch y PyG.\n",
    "\n",
    "Para eso instalamos las dependencias.\n",
    "\n",
    "Finalizamos instalando tsl desde GitHub, para estar al día con la última versión.\n",
    "\n",
    "Ademas descargamos un utility que necesitaremos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd65bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "# Install PyG dependencies\n",
    "%pip install -q torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html -f https://data.pyg.org/whl/torch-${TORCH}+cpu.html\n",
    "%pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# Install tsl from source\n",
    "%pip install -q git+https://github.com/TorchSpatiotemporal/tsl.git\n",
    "!wget -q --show-progress -O notebook_utils.py https://raw.githubusercontent.com/TorchSpatiotemporal/tsl/refs/heads/dev/examples/notebooks/_notebook_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbaf60",
   "metadata": {},
   "source": [
    "Nos remitimos a las guías de instalación de [tsl](https://torch-spatiotemporal.readthedocs.io/en/latest/usage/quickstart.html) y [PyG](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html) para la configuración en otros entornos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370d2ed",
   "metadata": {},
   "source": [
    "## Verificacion\n",
    "<hr>\n",
    "<h2 style=\"color: red\">IMPORTANTE: Se debe reiniciar el kernel para aplicar los cambios de las librerias</h2>\n",
    "\n",
    "Comprobemos si todo está bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0415125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsl\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"  PyG version: {torch_geometric.__version__}\")\n",
    "print(f\"  tsl version: {tsl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cebcfc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Cargar y Preprocesar Data**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902a7cb",
   "metadata": {},
   "source": [
    "## Cargar un dataset tabular\n",
    "<hr>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/TorchSpatiotemporal/tsl/main/docs/source/_static/img/tsl_logo.svg\" width=\"25px\" align=\"center\"/> tsl incluye una variedad de conjuntos de datos populares en la bibliografía. Puedes encontrarlos en el submódulo [`tsl.datasets`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5de252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl import datasets\n",
    "print(\"Datasets in tsl:\", *datasets.dataset_classes, sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d3460",
   "metadata": {},
   "source": [
    "Para este ejercicio usaremos el conjunto de datos [MetrLA](https://paperswithcode.com/sota/traffic-prediction-on-metr-la), un punto de referencia (benchmark) ampliamente utilizado para la predicción del tráfico. Este conjunto de datos consiste en lecturas de la velocidad del tráfico de 207 sensores en las autopistas del condado de Los Ángeles, agregadas en intervalos de 5 minutos durante un periodo de 4 meses (de marzo a junio de 2012).\n",
    "\n",
    "Cargar el conjunto de datos es así de simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.datasets import MetrLA\n",
    "\n",
    "dataset = MetrLA(root='./data')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f42ea6",
   "metadata": {},
   "source": [
    "Todos los conjuntos de datos en tsl son subclases de la clase raíz [`tsl.datasets.Dataset`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/datasets_prototypes.html#tsl.datasets.prototypes.Dataset), las cuales exponen APIs útiles para conjuntos de datos espacio-temporales. Podemos ver que los datos están organizados en un array tridimensional, con:\n",
    "\n",
    "* **34.272** pasos de tiempo (1 cada 5 minutos durante 4 meses)\n",
    "* **207** nodos (los detectores o sensores)\n",
    "* **1** canal (la velocidad detectada)\n",
    "\n",
    "¡Genial! Además de almacenar los datos de interés, el conjunto de datos viene con herramientas útiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac07092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sampling period: {dataset.freq}\")\n",
    "print(f\"Has missing values: {dataset.has_mask}\")\n",
    "print(f\"Percentage of missing values: {(1 - dataset.mask.mean()) * 100:.2f}%\")\n",
    "print(f\"Has exogenous variables: {dataset.has_covariates}\")\n",
    "print(f\"Covariates: {', '.join(dataset.covariates.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214cd9ae",
   "metadata": {},
   "source": [
    "Sampling period: <5 * minutes> \n",
    "- Esto confirma la frecuencia de los datos. Tienes una nueva medición cada 5 minutos.\n",
    "\n",
    "Has missing values: True y Percentage of missing values: 8.11%\n",
    "- Esto es súper importante. Los datos del mundo real casi nunca son perfectos. Aquí se confirma que faltan algunos datos (un sensor pudo fallar, hubo un error de transmisión, etc.).\n",
    "- El dataset tiene una \"máscara\" (dataset.mask) que te dirá exactamente qué valores faltan para que puedas manejarlos correctamente más adelante.\n",
    "\n",
    "Has exogenous variables: True y Covariates: 'dist'\n",
    "- Variables exógenas (o covariables) son datos adicionales que no son lo que quieres predecir (la velocidad), pero que pueden ayudar al modelo a predecir mejor.\n",
    "- Aquí, te dice que tienes una covariable llamada 'dist'. Esta es casi con seguridad una matriz de distancia. Es una tabla que le dice al modelo qué tan lejos está cada sensor de todos los demás sensores. Esta información es CRUCIAL para que el modelo entienda la estructura espacial de la red de carreteras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ac39a1",
   "metadata": {},
   "source": [
    "Veamos la salida. Sabemos que el conjunto de datos tiene entradas faltantes, siendo `dataset.mask` un indicador binario asociado con cada paso de tiempo, nodo y canal (donde los unos indican valores válidos).\n",
    "\n",
    "Además, el conjunto de datos tiene un atributo de **covariable** (es decir, variables exógenas) – la matriz de distancias – que contiene las distancias por pares entre los sensores.\n",
    "\n",
    "Puedes acceder a las covariables mediante `dataset.{nombre_covariable}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8099b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import *\n",
    "print_matrix(dataset.dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d385a85",
   "metadata": {},
   "source": [
    "Esta matriz es el componente espacial de tu modelo. Sin ella, el modelo solo vería 207 series de tiempo de velocidad de tráfico independientes. No tendría idea de que el sensor 5 está al lado del sensor 6.\n",
    "\n",
    "Con esta matriz, el modelo puede \"aprender\" cómo se propaga el tráfico. Entenderá que una congestión en el sensor `i` probablemente afectará en los próximos minutos a su vecino, el sensor `j`, pero no afectará directamente al sensor `k`, que está al otro lado de la ciudad (inf).\n",
    "\n",
    "Esta es la información que utilizará nuestra Red Neuronal de Grafos (GNN) para pasar mensajes entre los nodos (sensores) y hacer predicciones que consideren tanto el tiempo como el espacio.\n",
    "\n",
    "Podemos decir que la matriz almacena la distancia por pares entre los sensores, donde `inf` denota dos sensores no vecinos.\n",
    "\n",
    "Ahora veamos qué aspecto tienen los nodos de manera grafica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Paso 1: Cargar los datos de las ubicaciones ---\n",
    "try:\n",
    "    # Cargamos las coordenadas geográficas de los sensores desde un archivo CSV\n",
    "    locations_df = pd.read_csv('./data/locations.csv')\n",
    "    x_coords = locations_df['longitude'].values\n",
    "    y_coords = locations_df['latitude'].values\n",
    "\n",
    "    # --- Paso 2: Obtener la matriz de conexiones (adyacencia) ---\n",
    "    # Esto usa la variable 'dataset' que cargamos en los primeros pasos.\n",
    "    adjacency_matrix = np.where(dataset.dist == np.inf, 0, 1)\n",
    "    # Nos aseguramos de que no haya auto-conexiones (diagonal en 0)\n",
    "    np.fill_diagonal(adjacency_matrix, 0)\n",
    "    \n",
    "    # --- Paso 3: Dibujar el gráfico geográfico ---\n",
    "    print(\"Generando el mapa geográfico de los sensores...\")\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    # Dibujar las conexiones entre los nodos\n",
    "    for i in range(adjacency_matrix.shape[0]):\n",
    "        for j in range(i + 1, adjacency_matrix.shape[1]):\n",
    "            # Si hay un 1 en la matriz de adyacencia, significa que los nodos i y j son vecinos\n",
    "            if adjacency_matrix[i, j] == 1:\n",
    "                # Dibujamos una línea entre sus coordenadas geográficas\n",
    "                plt.plot([x_coords[i], x_coords[j]], [y_coords[i], y_coords[j]], \n",
    "                         alpha=0.5, linewidth=0.8)\n",
    "\n",
    "    # Dibujar los nodos (sensores) encima de las líneas\n",
    "    plt.scatter(x_coords, y_coords, s=25, c='blue', zorder=2, label='Sensores')\n",
    "\n",
    "    # Añadir etiquetas y título\n",
    "    plt.title(\"Distribución Geográfica de los Sensores de Tráfico (MetrLA)\", fontsize=16)\n",
    "    plt.xlabel(\"Longitud\", fontsize=12)\n",
    "    plt.ylabel(\"Latitud\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Esto asegura que el mapa no se vea deformado (la escala de los ejes es la misma)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # Mostramos el gráfico final\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'locations.csv' no fue encontrado. Por favor, asegúrate de subirlo.\")\n",
    "except NameError:\n",
    "    print(\"\\nError: La variable 'dataset' no está definida.\")\n",
    "    print(\"Por favor, ejecuta de nuevo la celda que carga el dataset MetrLA.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77581587",
   "metadata": {},
   "source": [
    "Ahora veamos qué aspecto tienen las lecturas de velocidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataframe()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3289413",
   "metadata": {},
   "source": [
    "Para entenderlo mucho mejor, veamos la grafica de las velocidades de algunos sensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionamos algunos sensores para graficar\n",
    "sensor_indices = [0, 50, 100]\n",
    "days_to_plot = 2\n",
    "points_per_day = 24 * (60 // 5)\n",
    "time_steps_to_plot = points_per_day * days_to_plot\n",
    "time_axis = dataset.target.index[:time_steps_to_plot]\n",
    "\n",
    "# --- Graficar ---\n",
    "plt.figure(figsize=(15, 5))\n",
    "for idx in sensor_indices:\n",
    "    speed_data = dataset.target.values[:time_steps_to_plot, idx]\n",
    "    plt.plot(time_axis, speed_data, label=f'Sensor #{idx}')\n",
    "\n",
    "plt.title(f\"Comparación de Velocidad de algunos sensores durante {days_to_plot} días\")\n",
    "plt.xlabel(\"Pasos de Tiempo (1 paso = 5 minutos)\")\n",
    "plt.ylabel(\"Velocidad de Tráfico\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d484cc2",
   "metadata": {},
   "source": [
    "### Conectando sensores\n",
    "\n",
    "Además de las series temporales, para usar correctamente los modelos basados en grafos, necesitamos __conectar__ los nodos de alguna manera.\n",
    "\n",
    "Con el método [`dataset.get_similarity()`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/datasets_prototypes.html#tsl.datasets.prototypes.Dataset.get_similarity) podemos recuperar las similitudes de los nodos calculadas con diferentes métodos. Los métodos de similitud disponibles para un conjunto de datos se pueden encontrar en `dataset.similarity_options`, mientras que el predeterminado está en `dataset.similarity_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Default similarity: {dataset.similarity_score}\")\n",
    "print(f\"Available similarity options: {dataset.similarity_options}\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "sim = dataset.get_similarity(\"distance\")  # or dataset.compute_similarity()\n",
    "\n",
    "print(\"Similarity matrix W:\")\n",
    "print_matrix(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454310b",
   "metadata": {},
   "source": [
    "Con este método, calculamos el peso $w_t^{i,j}$ de la arista que conecta el nodo $i$-ésimo y el $j$-ésimo como<br>\n",
    "$$\n",
    "w^{i,j} = \\left\\{\\begin{array}{cl}\n",
    "     \\exp \\left(-\\frac{\\operatorname{dist}\\left(i, j\\right)^{2}}{\\gamma}\\right) & \\operatorname{dist}\\left(i, j\\right) \\leq \\delta  \\\\\n",
    "     0 & \\text{en otro caso}\n",
    "\\end{array}\\right. ,\n",
    "$$<br>\n",
    "donde $\\operatorname{dist}\\left(i, j\\right)$ es la distancia entre el nodo $i$-ésimo y el $j$-ésimo, $\\gamma$ controla el ancho del kernel y $\\delta$ es un umbral. Nótese que en este caso la matriz de similitud no es simétrica, ya que la matriz de distancias preprocesada original tampoco lo es.\n",
    "\n",
    "Hasta aquí todo bien, ahora podemos construir una matriz de adyacencia a partir de la similitud calculada.\n",
    "\n",
    "El método [`dataset.get_connectivity()`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/datasets_prototypes.html#tsl.datasets.prototypes.Dataset.get_connectivity) – que llama a `dataset.get_similarity()` internamente – proporciona opciones útiles de preprocesamiento y, finalmente, devuelve una matriz de adyacencia posiblemente dispersa y posiblemente ponderada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ebc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity = dataset.get_connectivity(threshold=0.1,\n",
    "                                        include_self=False,\n",
    "                                        normalize_axis=1,\n",
    "                                        layout=\"edge_index\")\n",
    "print(connectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a30dc2",
   "metadata": {},
   "source": [
    "Veamos qué sucede con esta llamada a la función:\n",
    "\n",
    "1. calcula la matriz de similitud como antes;\n",
    "2. establece en 0 los valores por **debajo** de 0.1 (`threshold=0.1`);\n",
    "3. **elimina** los auto-bucles (`include_self=False`);\n",
    "4. **normaliza** los pesos de las aristas por el **grado de entrada** de los nodos (`normalize_axis=1`);\n",
    "5. solicita el **formato disperso COO** de PyG (`layout=\"edge_index\"`)\n",
    "\n",
    "La matriz de conectividad con el formato `edge_index` se proporciona en formato COO, adoptando la convención y notación utilizada en PyTorch Geometric. La conectividad devuelta es una tupla (`edge_index`, `edge_weight`), donde `edge_index` enumera todas las aristas como pares de nodos origen-destino (dimensiones `[2, E]`) y `edge_weight` (dimensión `[E]`) almacena los pesos correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, edge_weight = connectivity\n",
    "\n",
    "print(f'edge_index {edge_index.shape}:\\n', edge_index)\n",
    "print(f'edge_weight {edge_weight.shape}:\\n', edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789f70f",
   "metadata": {},
   "source": [
    "El formato COO representa el grafo usando principalmente dos tensores (o listas):\n",
    "\n",
    "`edge_index`: Este es el corazón del formato COO. Es una lista de coordenadas que te dice qué nodos están conectados. Tiene dos filas:\n",
    "- Fila 0: El nodo de origen de la conexión.\n",
    "- Fila 1: El nodo de destino de la conexión.\n",
    "\n",
    "`edge_weight`: Esta es una lista que contiene el \"peso\" o las características de cada conexión listada en edge_index.\n",
    "\n",
    "Veamos ahora de manera grafica como estan interconectados estos nodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Creamos el diccionario 'pos' que networkx necesita: {node_id: (longitude, latitude)}\n",
    "pos = {i: (lon, lat) for i, lon, lat in zip(locations_df.index, locations_df['longitude'], locations_df['latitude'])}\n",
    "\n",
    "num_nodes = locations_df.shape[0]\n",
    "\n",
    "# --- Paso 3: Construir el objeto de grafo en NetworkX ---\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(num_nodes))\n",
    "for i in range(edge_index.shape[1]):\n",
    "    source = edge_index[0, i]\n",
    "    target = edge_index[1, i]\n",
    "    weight = edge_weight[i]\n",
    "    G.add_edge(source, target, weight=weight)\n",
    "\n",
    "# --- Paso 4: Dibujar el grafo sobre el mapa geográfico ---\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Extraemos los pesos para darles color y grosor a las aristas\n",
    "weights = np.array([G[u][v]['weight'] for u, v in G.edges()])\n",
    "\n",
    "# Dibujamos los nodos (sensores) en sus coordenadas reales\n",
    "nx.draw_networkx_nodes(G, pos, node_color='blue', node_size=20, ax=ax)\n",
    "\n",
    "# Dibujamos las aristas usando los pesos para el color y el grosor\n",
    "edges = nx.draw_networkx_edges(\n",
    "    G,\n",
    "    pos,  # <-- ¡Aquí está la magia! Usamos las coordenadas geográficas\n",
    "    edge_color=weights,\n",
    "    width=weights * 10,  # Multiplicamos para que el grosor sea más notable\n",
    "    edge_cmap=plt.cm.viridis,\n",
    "    alpha=0.8,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# --- Paso 5: Añadir la barra de color y los detalles finales ---\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=weights.min(), vmax=weights.max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, shrink=0.7)\n",
    "cbar.set_label('Fuerza de la Conexión (Edge Weight)', rotation=270, labelpad=15)\n",
    "\n",
    "ax.set_title(\"Mapa Geográfico Ponderado de la Red de Sensores\", fontsize=16)\n",
    "ax.set_xlabel(\"Longitud\", fontsize=12)\n",
    "ax.set_ylabel(\"Latitud\", fontsize=12)\n",
    "ax.grid(True)\n",
    "ax.set_aspect('equal', adjustable='box') # Esencial para que el mapa no se deforme\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d565d",
   "metadata": {},
   "source": [
    "## Creando un conjunto de datos listo para PyTorch\n",
    "<hr>\n",
    "\n",
    "En esta sección, veremos cómo obtener **señales de grafos espaciotemporales** que luego se entregan como entrada a una red neuronal (por ejemplo, una STGNN) a partir de un conjunto de datos de este tipo.\n",
    "\n",
    "La primera clase que nos ayuda es [`tsl.data.SpatioTemporalDataset`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/data_pytorch_datasets.html#tsl.data.SpatioTemporalDataset). Esta clase es una subclase de [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) y se encarga de mapear un conjunto de datos tabular representado en tu formato preferido (por ejemplo, un array de numpy, un dataframe de pandas o el mencionado [`tsl.datasets.Dataset`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/datasets_prototypes.html#tsl.datasets.prototypes.Dataset)) a una implementación lista para PyTorch.\n",
    "\n",
    "En particular, un objeto `SpatioTemporalDataset` se puede usar para lograr lo siguiente:\n",
    "* Realizar operaciones de **manipulación de datos** necesarias para alimentar los datos a un módulo de PyTorch (p. ej., convertir datos a `torch.tensor`, manejar `shapes` posiblemente diferentes, sincronizar datos temporales).\n",
    "* Crear **muestras `(input, target)`** ara el aprendizaje supervisado siguiendo el enfoque de [**sliding window**](https://torch-spatiotemporal.readthedocs.io/en/latest/usage/spatiotemporal_dataset.html#sliding-window).\n",
    "* Definir cómo se deben **organizar** los datos en una **señal de grafo espaciotemporal** (p. ej., cuáles son las entradas y los objetivos, cómo los atributos de los nodos y las variables covariables se mapean en un único grafo).\n",
    "* **Preprocesar** los datos antes de crear una **señal de grafo espaciotemporal** aplicando operaciones de [**transformacion**](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/transforms.html) o [**escalamiento**](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/data_preprocessing.html).\n",
    "\n",
    "Veamos cómo pasar de un `Dataset` a un `SpatioTemporalDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab37f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data import SpatioTemporalDataset\n",
    "\n",
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      connectivity=connectivity,\n",
    "                                      mask=dataset.mask,\n",
    "                                      horizon=12,\n",
    "                                      window=12,\n",
    "                                      stride=1)\n",
    "print(torch_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11df037",
   "metadata": {},
   "source": [
    "La línea `torch_dataset = SpatioTemporalDataset(...)` crea un objeto que contiene miles de muestras de entrenamiento. Lo hace utilizando una técnica llamada ventana deslizante (sliding window), que se ilustra como ejemplo en el diagrama que encontramos debajo. \n",
    "\n",
    "<h5 style=\"color: red;\">La imagen es referencial, no es una representacion fiel de nuestros datos, es solamente para entender la tecnica de sliding window que utilizaremos</h5>\n",
    "\n",
    "Veamos los parámetros clave y cómo se relacionan con la imagen:\n",
    "\n",
    "`target=dataset.dataframe()`: Aquí le pasas los datos brutos de las series temporales de los 207 sensores.\n",
    "\n",
    "`connectivity=connectivity`: Le entregas la estructura del grafo (el `edge_index` y `edge_weight`). Esta es la parte espacial (Spatio).\n",
    "\n",
    "`mask=dataset.mask`: Es un mapa de datos faltantes. Le dice al modelo qué valores en tu serie de tiempo son reales y cuáles deben ser ignorados porque no son válidos (por ejemplo, un sensor se apagó o hubo un error de lectura).\n",
    "\n",
    "`window=12`: Es la ventana de observación (el cuadro azul en el diagrama). Para cada ejemplo de entrenamiento, el modelo mirará los 12 datos más recientes del pasado. Esta es la parte temporal (Temporal).\n",
    "\n",
    "`horizon=12`: Es el horizonte de predicción (el cuadro verde). Basándose en la window de 12 pasos, el modelo intentará predecir los siguientes 12 pasos en el futuro.\n",
    "\n",
    "`stride=1`: Es el paso de deslizamiento. Indica que para crear el siguiente ejemplo de entrenamiento, la ventana se desliza solo un paso hacia el futuro. Esto permite generar muchos más ejemplos a partir de los mismos datos.\n",
    "\n",
    "<hr>\n",
    "\n",
    "El resultado que se imprime, `SpatioTemporalDataset(n_samples=34249, n_nodes=207, n_channels=1)`, indica lo que se ha creado:\n",
    "\n",
    "`n_samples=34249`: Al aplicar esta ventana deslizante sobre toda tu serie temporal, se han generado 34,249 muestras de entrenamiento individuales. Cada muestra es un par (ventana de 12 pasos, horizonte de 12 pasos).\n",
    "\n",
    "`n_nodes=207`: Confirma que cada una de esas muestras contiene datos de tus 207 sensores.\n",
    "\n",
    "`n_channels=1`: Indica que cada sensor mide una sola variable (en nuestro caso la velocidad) en cada instante de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85891530",
   "metadata": {},
   "source": [
    "Como puedes ver, el número de muestras no es el mismo que el número de pasos que tenemos en el conjunto de datos. De hecho, dividimos la serie temporal histórica con una **sliding window** de **12 pasos de tiempo** para la **ventana de observación hacia atrás** (`window=12`), con un **horizonte** correspondiente de **12 pasos de tiempo** (`horizon=12`). Por lo tanto, una única muestra abarca un total de 24 pasos de tiempo. El parámetro `stride` establece cuántos pasos de tiempo transcurren entre dos muestras consecutivas. La siguiente imagen ayuda a visualizar cómo estos (y otros) parámetros afectan al particionamiento de la serie temporal original en muestras.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://torch-spatiotemporal.readthedocs.io/en/latest/_images/sliding_window.svg\" width=\"500em\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96161b",
   "metadata": {},
   "source": [
    "## Señales de grafos espaciotemporales en tsl\n",
    "\n",
    "Ahora tenemos un conjunto de datos basado en PyTorch que contiene una colección de señales de grafos espaciotemporales. Podemos obtener muestras de la misma manera que obtenemos elementos de una lista de Python. Veamos en detalle el diseño de una muestra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch_dataset[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8898d",
   "metadata": {},
   "source": [
    "Una muestra es de tipo [`tsl.data.Data`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/data_objects.html#tsl.data.Data), la clase base para representar señales de grafos espaciotemporales en tsl. Esta clase extiende [`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data), conservando todas sus funcionalidades y añadiendo utilidades para el procesamiento de datos espaciotemporales. Las principales API de `Data` incluyen:\n",
    "\n",
    "* **`Data.input`**: vista de los tensores almacenados en `Data` que están destinados a servir como entrada para el modelo. En el caso más simple de una única matriz de atributos de nodo, podríamos tener simplemente `Data.input.x`.\n",
    "* **`Data.target`**: vista de los tensores almacenados en `Data` utilizados como etiquetas para entrenar el modelo. En el caso común de una única etiqueta, podríamos tener simplemente `Data.input.y`.\n",
    "* **`Data.edge_index`**: conectividad del grafo en formato COO (es decir, como pares de nodos).\n",
    "* **`Data.edge_weight`**: pesos de la conectividad del grafo, si los hay.\n",
    "* **`Data.mask`**: máscara binaria que indica los datos en `Data.target.y` que se utilizarán como verdad fundamental (ground-truth) para la pérdida (el valor predeterminado es `None`).\n",
    "\n",
    "Ninguno de estos atributos es obligatorio y se pueden añadir atributos personalizados sin problemas.\n",
    "\n",
    "Veamos con más detalle cómo se compone cada uno de estos atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea886ae",
   "metadata": {},
   "source": [
    "#### Input y Target\n",
    "\n",
    "`Data.input` y `Data.target` proporcionan una **vista** sobre el almacenamiento único (compartido) en `Data`, de tal manera que la misma clave en `Data.input` y `Data.target` no puede hacer referencia a objetos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.input.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.target.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52689d13",
   "metadata": {},
   "source": [
    "Veamos algunos datos de nuestra muestra de forma grafica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Lista de los sensores que quieres visualizar\n",
    "sensors_to_plot = [0, 50, 100]\n",
    "colors = ['royalblue', 'orangered', 'forestgreen'] # Colores para cada sensor\n",
    "\n",
    "# --- Creación del Gráfico ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Bucle para graficar cada sensor de la lista\n",
    "for i, sensor_id in enumerate(sensors_to_plot):\n",
    "    # Extrae los datos de entrada ('x') y de salida ('y') para el sensor actual\n",
    "    input_data = sample.input['x'][:, sensor_id].squeeze().numpy()\n",
    "    target_data = sample.target['y'][:, sensor_id].squeeze().numpy()\n",
    "\n",
    "    # Crea los ejes de tiempo para el gráfico\n",
    "    input_timesteps = np.arange(len(input_data))\n",
    "    target_timesteps = np.arange(len(input_data), len(input_data) + len(target_data))\n",
    "\n",
    "    # Grafica la serie de entrada para el sensor actual\n",
    "    plt.plot(input_timesteps, input_data, 'o-', label=f'Input (Sensor #{sensor_id})', color=colors[i], alpha=0.8)\n",
    "\n",
    "    # Grafica la serie objetivo para el sensor actual\n",
    "    plt.plot(target_timesteps, target_data, 's--', label=f'Target (Sensor #{sensor_id})', color=colors[i], alpha=0.8)\n",
    "\n",
    "# Añade una línea vertical para separar claramente el input del target\n",
    "plt.axvline(x=input_timesteps[-1], color='gray', linestyle=':', linewidth=2, label='Punto de Predicción')\n",
    "\n",
    "plt.title(f'Ventana de Entrada y Horizonte de Predicción para Sensores Múltiples')\n",
    "plt.xlabel('Pasos de Tiempo (Timesteps)')\n",
    "plt.ylabel('Valor del Sensor')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffa5e3",
   "metadata": {},
   "source": [
    "## Preparando el conjunto de datos para el entrenamiento\n",
    "<hr>\n",
    "\n",
    "Generalmente, antes de ejecutar un experimento, hay dos pasos de preprocesamiento bastante comunes:\n",
    "\n",
    "* **dividir** el conjunto de datos en conjuntos de **entrenamiento/validación/prueba**;\n",
    "* **preprocesamiento de datos** (escalar/normalizar datos, eliminar tendencias).\n",
    "\n",
    "En tsl, estas operaciones son gestionadas por el [`tsl.data.SpatioTemporalDataModule`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/data_datamodule.html#tsl.data.datamodule.SpatioTemporalDataModule), que se basa en el [`LightningDataModule`](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.core.LightningDataModule.html#pytorch_lightning.core.LightningDataModule) de [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/stable/). Un `DataModule` nos permite estandarizar y hacer consistentes las divisiones de entrenamiento, validación y prueba, la preparación de datos y las transformaciones en diferentes entornos y experimentos.\n",
    "\n",
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c78d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize data using mean and std computed over time and node dimensions\n",
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n",
    "\n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.1, test_len=0.2)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77765b90",
   "metadata": {},
   "source": [
    "Durante el `setup`, el datamodule realiza las siguientes operaciones:\n",
    "\n",
    "1. Lleva a cabo la división del conjunto de datos en conjuntos de entrenamiento/validación/prueba de acuerdo con el proporcionado [`Splitter`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/data_datamodule.html#tsl.data.datamodule.splitters.Splitter).\n",
    "2. Ajusta todos los `Scalers` a los datos de entrenamiento en `torch_dataset` correspondientes a la clave de los escaladores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff45767",
   "metadata": {},
   "source": [
    "`SpatioTemporalDataModule`: Es un organizador de alto nivel que prepara el dataset para el entrenamiento. Automatiza dos pasos críticos: el escalado de los datos y su división en conjuntos de entrenamiento, validación y prueba.\n",
    "\n",
    "`scalers`:\n",
    "- `StandardScaler` normaliza los datos para que todos los sensores operen en una escala comparable.\n",
    "- Transforma los datos para que tengan una media de 0 y una desviación estándar de 1 (Z-score).\n",
    "- Evita que el modelo le dé más importancia a sensores con valores numéricos más altos, asegurando que el aprendizaje se base en los patrones y no en la magnitud. Es como hacer que todos los sensores \"hablen el mismo idioma numérico\".\n",
    "\n",
    "`splitter`:\n",
    "- `TemporalSplitter` divide el dataset cronológicamente para una evaluación justa del modelo.\n",
    "- Separa los datos en tres bloques secuenciales:\n",
    "    - Entrenamiento (Train): Los datos más antiguos, para que el modelo aprenda.\n",
    "    - Validación (Validation): Datos intermedios, para ajustar el modelo durante el entrenamiento.\n",
    "    - Prueba (Test): Los datos más recientes, para evaluar el rendimiento final del modelo en información completamente nueva.\n",
    "\n",
    "`batch_size` (Tamaño del Lote):\n",
    "- Define cuántas muestras de datos (pares de ventana/horizonte) se procesan simultáneamente en cada paso del entrenamiento.\n",
    "- `batch_size=64`: Significa que el modelo mirará 64 ejemplos a la vez para actualizar sus parámetros.\n",
    "- Es un equilibrio entre velocidad y memoria. Lotes más grandes pueden acelerar el entrenamiento pero consumen más memoria RAM/VRAM. Lotes pequeños son más lentos pero más ligeros. Es como comerse un pastel en rebanadas manejables en lugar de todo de un solo bocado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4da23",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Construcción de Redes Neuronales de Grafos Espaciotemporales**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076de43b",
   "metadata": {},
   "source": [
    "## Diseñando una STGNN personalizada\n",
    "<hr>\n",
    "\n",
    "Manos a la obra y creemos nuestra primera STGNN simple! Seguiremos el paradigma **Tiempo-luego-Espacio (Time-then-Space)**.Usamos una GRU compartida entre los nodos para procesar la dimensión temporal. Esto nos dará como salida un único vector de características para cada nodo, que luego se propaga a través del grafo subyacente utilizando una GNN Convolucional de Difusión. Antes y después, añadimos transformaciones lineales para codificar las características de entrada y decodificar las representaciones aprendidas. También hacemos uso de **incrustaciones de nodos (node embeddings)** (parámetros libres aprendidos individualmente para cada nodo) para hacer de nuestra STGNN un **modelo global-local** ([Cini et al., 2023](https://arxiv.org/abs/2302.04071)).\n",
    "\n",
    "Todas las capas que necesitamos se proporcionan dentro de `tsl.nn`. Usamos:\n",
    "* [`RNN`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/nn_blocks.html#tsl.nn.blocks.encoders.RNN) de `tsl.nn.blocks.encoders` para la GRU;\n",
    "* [`DiffConv`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/nn_layers.html#tsl.nn.layers.graph_convs.DiffConv) de `tsl.nn.layers.graph_convs` para la convolución de difusión;\n",
    "* `StaticGraphEmbedding` de `tsl.nn.base` para las incrustaciones de nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from tsl.nn.blocks import RNN, MLPDecoder\n",
    "from tsl.nn.layers import NodeEmbedding, DiffConv\n",
    "\n",
    "\n",
    "class TimeThenSpaceModel(nn.Module):\n",
    "    def __init__(self, input_size: int, n_nodes: int, horizon: int,\n",
    "                 emb_size: int = 16,\n",
    "                 hidden_size: int = 32,\n",
    "                 rnn_layers: int = 1,\n",
    "                 gnn_kernel: int = 2):\n",
    "        super(TimeThenSpaceModel, self).__init__()\n",
    "\n",
    "        self.node_embeddings = NodeEmbedding(n_nodes, emb_size)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Linear(input_size + emb_size, hidden_size)\n",
    "\n",
    "        # STMP\n",
    "        self.time_nn = RNN(input_size=hidden_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           n_layers=rnn_layers,\n",
    "                           cell='gru',\n",
    "                           return_only_last_state=True)\n",
    "\n",
    "        self.space_nn = DiffConv(in_channels=hidden_size,\n",
    "                                 out_channels=hidden_size,\n",
    "                                 k=gnn_kernel,\n",
    "                                 root_weight=True)\n",
    "        # Decoder\n",
    "        self.decoder = MLPDecoder(input_size=hidden_size + emb_size,\n",
    "                                  hidden_size=2 * hidden_size,\n",
    "                                  output_size=input_size,\n",
    "                                  horizon=horizon,\n",
    "                                  n_layers=1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x: [batch time nodes features]\n",
    "        b, t, n, f = x.size()\n",
    "        # Concatenate node embeddings to input\n",
    "        emb = self.node_embeddings(expand=(b, t, -1, -1))\n",
    "        x_emb = torch.cat([x, emb], dim=-1)\n",
    "        # Encoder\n",
    "        x_enc = self.encoder(x_emb)  # linear proj: x_enc = [x||emb]Θ + b\n",
    "        # STMP\n",
    "        h = self.time_nn(x_enc)  # temporal processing: x=[b t n f] -> h=[b n f]\n",
    "        z = self.space_nn(h, edge_index, edge_weight)  # spatial processing\n",
    "        # Decoder\n",
    "        emb = self.node_embeddings(expand=(b, -1, -1))\n",
    "        z_emb = torch.cat([z, emb], dim=-1)  # concatenate node embeddings to z\n",
    "        x_out = self.decoder(z_emb)  # linear proj: z=[b n f] -> x_out=[b n t⋅f]\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260fb111",
   "metadata": {},
   "source": [
    "Este código define la arquitectura de la red neuronal, el \"cerebro\" que aprenderá a predecir el futuro. El nombre del modelo, `TimeThenSpaceModel`, revela su estrategia: primero analiza los patrones a lo largo del tiempo para cada sensor de forma independiente, y luego combina esa información a través del espacio (el grafo de sensores).\n",
    "\n",
    "Aquí tienes un desglose de sus componentes y cómo funcionan juntos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6f41a",
   "metadata": {},
   "source": [
    "### Arquitectura del Modelo (__init__)\n",
    "Esta sección es como la lista de \"ingredientes\" o componentes del modelo. Cada uno es una capa especializada con una tarea específica.\n",
    "\n",
    "- `self.node_embeddings` (La Cédula de Identidad del Sensor): Esta capa crea un vector único y aprendible para cada uno de los 207 sensores. Esto le permite al modelo distinguir entre ellos y aprender características específicas de cada ubicación (por ejemplo, que un sensor en una autopista se comporta diferente a uno en una calle residencial).\n",
    "- `self.encoder` (La Capa de Preparación) Fija: Es una capa lineal simple que toma los datos de entrada junto con la \"cédula de identidad\" del sensor y los proyecta a un espacio de mayor dimensión (`hidden_size`). Su función es preparar y enriquecer la información para las capas más complejas que vienen después.\n",
    "- `self.time_nn` (El Analista Temporal): Este es el primer componente principal. Utiliza una red neuronal recurrente (específicamente una GRU) para analizar la secuencia de datos pasados (la ventana de 12 pasos) de cada sensor por separado. Su trabajo es \"leer\" la historia temporal y resumirla en un único vector de estado que captura los patrones temporales (tendencias, estacionalidad, etc.).\n",
    "- `self.space_nn` (El Comunicador Espacial): Este es el segundo componente principal. Es una Red Neuronal de Grafos (GNN). Toma los resúmenes temporales de todos los sensores y permite que \"hablen\" entre sí a través de las conexiones del grafo (`edge_index`). Un sensor ahora puede ajustar su estado basándose en la información de sus vecinos, aprendiendo así patrones espaciales (por ejemplo, \"si el tráfico aumenta en el sensor A, es probable que aumente en el sensor B en el futuro cercano\").\n",
    "- `self.decoder` (El Pronosticador): Es la capa final. Toma la representación combinada de tiempo y espacio, la enriquece de nuevo con la \"cédula\" del sensor, y la utiliza para generar la predicción final para el horizonte de 12 pasos en el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9f751",
   "metadata": {},
   "source": [
    "## Flujo de Datos (forward)\n",
    "Esta sección describe el \"viaje\" que realizan los datos a través del modelo en cada paso de entrenamiento.\n",
    "\n",
    "- Enriquecer: Los datos de entrada x se combinan con los `node_embeddings`. Ahora cada dato no solo tiene su valor, sino también una etiqueta de qué sensor proviene.\n",
    "- Codificar: La mezcla de datos y embeddings pasa por el `encoder` para prepararse.\n",
    "- Procesar el TIEMPO: La `time_nn` (GRU) procesa la secuencia temporal de cada sensor y la colapsa en un único vector de resumen `h`. En este punto, el modelo ha entendido la historia de cada sensor.\n",
    "- Procesar el ESPACIO: El vector `h` de cada sensor se pasa a la `space_nn` (GNN). Los sensores intercambian información con sus vecinos, produciendo un nuevo vector `z` que ahora contiene conocimiento espacio-temporal. En este punto, el modelo ha entendido cómo se influyen los sensores entre sí.\n",
    "- Decodificar y Predecir: El vector final `z` se combina una última vez con los embeddings y se entrega al `decoder`, que genera la predicción final `x_out` con la forma `[batch, horizonte, nodos, features]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafa435",
   "metadata": {},
   "source": [
    "En resumen, el modelo implementa una estrategia muy intuitiva: primero entiende la historia individual de cada sensor y luego usa las conexiones del grafo para entender cómo el vecindario afecta a cada uno antes de hacer una predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9880d1",
   "metadata": {},
   "source": [
    "Podemos jugar con los hiperparámetros y crear una instancia de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6defeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 16      #@param\n",
    "hidden_size = 32  #@param\n",
    "rnn_layers = 1     #@param\n",
    "gnn_kernel = 2     #@param\n",
    "\n",
    "input_size = torch_dataset.n_channels   # 1 channel\n",
    "n_nodes = torch_dataset.n_nodes         # 207 nodes\n",
    "horizon = torch_dataset.horizon         # 12 time steps\n",
    "\n",
    "stgnn = TimeThenSpaceModel(input_size=input_size,\n",
    "                           n_nodes=n_nodes,\n",
    "                           horizon=horizon,\n",
    "                           emb_size=emb_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           rnn_layers=rnn_layers,\n",
    "                           gnn_kernel=gnn_kernel)\n",
    "print(stgnn)\n",
    "print_model_size(stgnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6737feb",
   "metadata": {},
   "source": [
    "Veamos ahora una única muestra de entrenamiento (la muestra 0) para un nodo específico (el nodo 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inputs_and_target(torch_dataset, plot_neighbors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b3681",
   "metadata": {},
   "source": [
    "**Gráfico 1 (Arriba Izquierda)**: Dibuja los datos de entrada del node_idx principal.\n",
    "\n",
    "**Gráfico 2 (Arriba Derecha)**: Dibuja el target en su escala original, sin normalizar.\n",
    "\n",
    "**Gráfico 3 (Abajo Izquierda)**: Si plot_neighbors es True, dibuja las series de tiempo de todos los vecinos del node_idx superpuestas. Utiliza la función auxiliar get_darker_shades para darles a las líneas de los vecinos colores similares pero distinguibles.\n",
    "\n",
    "**Gráfico 4 (Abajo Derecha)**: Dibuja el scaled_target, la versión normalizada del objetivo que el modelo realmente intenta predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd195809",
   "metadata": {},
   "source": [
    "Bien, hemos cargado los datos y construido un modelo, ¡así que vamos a entrenarlo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a018a73",
   "metadata": {},
   "source": [
    "## Configurando el entrenamiento\n",
    "<hr>\n",
    "\n",
    "Ahora estamos listos para entrenar nuestro modelo. Configuramos el procedimiento de entrenamiento como prefiramos; a continuación, usaremos el Trainer de PyTorch Lightning para reducir la carga del trabajo sucio. Recordemos que tsl está altamente integrado con librerías basadas en PyTorch ampliamente utilizadas, como PyTorch Lightning y PyTorch Geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258d510",
   "metadata": {},
   "source": [
    "### El Predictor\n",
    "\n",
    "En tsl, los motores de inferencia se implementan como un [`LightningModule`](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.LightningModule.html#pytorch_lightning.core.LightningModule). [`tsl.engines.Predictor`](https://torch-spatiotemporal.readthedocs.io/en/latest/modules/engines.html#tsl.engines.Predictor) es una clase base que se puede extender para construir enfoques de pronóstico más complejos. \n",
    "\n",
    "Estos módulos están diseñados para encapsular modelos profundos con el fin de facilitar las fases de entrenamiento e inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6040cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.metrics.torch import MaskedMAE, MaskedMAPE, MaskedMetric\n",
    "from torchmetrics.functional.regression.r2 import _r2_score_update, _r2_score_compute\n",
    "from tsl.engines import Predictor\n",
    "import torch\n",
    "\n",
    "# 1. Usa esta versión final y completa de la clase R2\n",
    "class R2(MaskedMetric):\n",
    "    is_differentiable: bool = False\n",
    "    higher_is_better: bool = True\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(R2, self).__init__(metric_fn=lambda y_hat, y: None, **kwargs)\n",
    "        \n",
    "        # Registra los CUATRO estados que R2Score necesita\n",
    "        self.add_state(\"sum_squared_error\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"sum_error\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"residual\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_hat: torch.Tensor, y: torch.Tensor, mask: torch.Tensor) -> None:\n",
    "        # Aplica la máscara primero\n",
    "        if mask is not None:\n",
    "            mask = mask.bool()\n",
    "            y_hat = y_hat[mask]\n",
    "            y = y[mask]\n",
    "        \n",
    "        # Desempaca los CUATRO valores devueltos por la función de actualización\n",
    "        sum_squared_error, sum_error, residual, total = _r2_score_update(y_hat, y)\n",
    "\n",
    "        # Acumula cada estado\n",
    "        self.sum_squared_error += sum_squared_error\n",
    "        self.sum_error += sum_error\n",
    "        self.residual += residual\n",
    "        self.total += total\n",
    "\n",
    "    def compute(self) -> torch.Tensor:\n",
    "        # Pasa los CUATRO estados acumulados a la función de cálculo final\n",
    "        return _r2_score_compute(self.sum_squared_error, self.sum_error, self.residual, self.total)\n",
    "\n",
    "loss_fn = MaskedMAE()\n",
    "\n",
    "metrics = {'mae': MaskedMAE(),\n",
    "           'mape': MaskedMAPE(),\n",
    "           'mae_at_15': MaskedMAE(at=2),  # '2' indicates the third time step,\n",
    "                                          # which correspond to 15 minutes ahead\n",
    "           'mae_at_30': MaskedMAE(at=5),\n",
    "           'mae_at_60': MaskedMAE(at=11),\n",
    "           'r2': R2()}\n",
    "\n",
    "# setup predictor\n",
    "predictor = Predictor(\n",
    "    model=stgnn,                   # our initialized model\n",
    "    optim_class=torch.optim.Adam,  # specify optimizer to be used...\n",
    "    optim_kwargs={'lr': 0.001},    # ...and parameters for its initialization\n",
    "    loss_fn=loss_fn,               # which loss function to be used\n",
    "    metrics=metrics                # metrics to be logged during train/val/test\n",
    ")\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6c097",
   "metadata": {},
   "source": [
    "Ahora finalicemos los últimos detalles. Usamos [TensorBoard](https://www.tensorflow.org/tensorboard/) para registrar y visualizar métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=\"logs\", name=\"tsl_intro\", version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac660519",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a24a66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ae121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=64,\n",
    "    workers=12,\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='logs',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=2,\n",
    "                     logger=logger,\n",
    "                     # accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", # para windows\n",
    "                     accelerator=\"mps\", # para mac con chip m1/m2\n",
    "                     devices=1,\n",
    "                     limit_train_batches=1000,  # end an epoch after 1000 updates\n",
    "                     callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(predictor, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55929472",
   "metadata": {},
   "source": [
    "## Pruebas\n",
    "\n",
    "<hr>\n",
    "\n",
    "Ahora veamos cómo se comporta el modelo entrenado con datos nuevos y no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234450cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.serialization.add_safe_globals([\n",
    "#     tsl.metrics.torch.metrics.MaskedMAE,\n",
    "#     tsl.metrics.torch.metrics.MaskedMAPE,\n",
    "#     tsl.metrics.torch.functional.mape,\n",
    "#     torch.optim.Adam,\n",
    "#     jit_distributed_available,\n",
    "#     dim_zero_sum,\n",
    "#     functools.partial,\n",
    "#     torch.nn.functional.l1_loss,\n",
    "#     slice\n",
    "# ])\n",
    "\n",
    "# Now, your original code will work correctly and safely\n",
    "predictor.load_model(checkpoint_callback.best_model_path)\n",
    "predictor.freeze()\n",
    "\n",
    "trainer.test(predictor, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = dm.test_dataloader()\n",
    "predictor.load_model(checkpoint_callback.best_model_path)\n",
    "predictions_list = trainer.predict(model=predictor, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unimos los lotes en un solo tensor\n",
    "predictions = torch.cat([batch['y_hat'] for batch in predictions_list])\n",
    "\n",
    "print(f\"\\n✅ ¡Predicción completada! Forma del tensor: {predictions.shape}\")\n",
    "\n",
    "\n",
    "# --- Paso 3: Visualizar un resultado ---\n",
    "sample_idx = 0\n",
    "node_idx = 0\n",
    "\n",
    "prediction_sample = predictions[sample_idx, :, node_idx].squeeze().cpu().numpy()\n",
    "ground_truth_sample = dm.testset[sample_idx].target['y'][:, node_idx].squeeze().cpu().numpy()\n",
    "\n",
    "# ... (código del gráfico) ...\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(ground_truth_sample, 'o-', label='Valor Real', color='royalblue')\n",
    "plt.plot(prediction_sample, 's--', label='Predicción', color='orangered')\n",
    "plt.title(f'Comparación Predicción vs. Realidad (Muestra #{sample_idx}, Sensor #{node_idx})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff3714",
   "metadata": {},
   "source": [
    "Del grafico observamos que la prediccion no se asemeja demasiado a los valores reales.\n",
    "\n",
    "Esta es una situación muy común en el modelado de series temporales y es un excelente indicador de lo que tu modelo ha aprendido (o no ha aprendido).\n",
    "\n",
    "La predicción es tan plana porque el modelo ha descubierto que la estrategia más segura para minimizar el error promedio (usando una pérdida como MAE) es predecir el valor medio (o la media) de la serie temporal. No ha logrado capturar los patrones más complejos y volátiles (los picos y valles) de los datos reales.\n",
    "\n",
    "En resumen, es un caso clásico de underfitting.\n",
    "\n",
    "Analogía del Pronóstico del Tiempo 🌦️: Imagina a un meteorólogo novato que tiene mucho miedo a equivocarse. Si mira los datos históricos y ve que la temperatura promedio en tu ciudad es de 20°C, la forma más \"segura\" de no cometer un error garrafal es predecir \"20°C\" todos los días. Acertará en promedio, pero fallará en predecir los días de calor extremo o las olas de frío. Tu modelo está haciendo exactamente eso.\n",
    "\n",
    "## Las Causas Más Probables\n",
    "Capacidad del Modelo Insuficiente (Underfitting) 🧠: Esta es la causa más probable. El modelo (TimeThenSpaceModel) es demasiado simple para la complejidad de los datos de tráfico. Tiene muy pocas \"neuronas\" o \"capas\" para poder aprender las relaciones no lineales que causan los picos y valles. Con su capacidad actual, lo único que puede aprender es la tendencia central.\n",
    "\n",
    "Entrenamiento Insuficiente 📉: Es posible que no hayas entrenado el modelo durante suficientes épocas. Puede que estuviera empezando a aprender los patrones más finos, pero el entrenamiento se detuvo antes de que pudiera converger a una solución más compleja.\n",
    "\n",
    "Tasa de Aprendizaje (Learning Rate) no Óptima: Si la tasa de aprendizaje es demasiado baja, el modelo aprende tan lentamente que se queda atascado en la solución simple de predecir la media. Si es demasiado alta, sus ajustes son tan bruscos que nunca logra asentarse en los patrones complejos y vuelve a la media como punto de equilibrio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5e4c9",
   "metadata": {},
   "source": [
    "Esta es una situación muy común en el modelado de series temporales y es un excelente indicador de lo que tu modelo ha aprendido (o no ha aprendido).\n",
    "\n",
    "Tu predicción es tan plana porque el modelo ha descubierto que la estrategia más segura para minimizar el error promedio (usando una pérdida como MAE) es predecir el valor medio (o la media) de la serie temporal. No ha logrado capturar los patrones más complejos y volátiles (los picos y valles) de los datos reales.\n",
    "\n",
    "En resumen, es un caso clásico de underfitting.\n",
    "\n",
    "Analogía del Pronóstico del Tiempo 🌦️: Imagina a un meteorólogo novato que tiene mucho miedo a equivocarse. Si mira los datos históricos y ve que la temperatura promedio en tu ciudad es de 20°C, la forma más \"segura\" de no cometer un error garrafal es predecir \"20°C\" todos los días. Acertará en promedio, pero fallará en predecir los días de calor extremo o las olas de frío. Tu modelo está haciendo exactamente eso.\n",
    "\n",
    "## Las Causas Más Probables\n",
    "Capacidad del Modelo Insuficiente (Underfitting) 🧠: Esta es la causa más probable. El modelo (TimeThenSpaceModel) es demasiado simple para la complejidad de los datos de tráfico. Tiene muy pocas \"neuronas\" o \"capas\" para poder aprender las relaciones no lineales que causan los picos y valles. Con su capacidad actual, lo único que puede aprender es la tendencia central.\n",
    "\n",
    "Entrenamiento Insuficiente 📉: Es posible que no hayas entrenado el modelo durante suficientes épocas. Puede que estuviera empezando a aprender los patrones más finos, pero el entrenamiento se detuvo antes de que pudiera converger a una solución más compleja.\n",
    "\n",
    "Tasa de Aprendizaje (Learning Rate) no Óptima: Si la tasa de aprendizaje es demasiado baja, el modelo aprende tan lentamente que se queda atascado en la solución simple de predecir la media. Si es demasiado alta, sus ajustes son tan bruscos que nunca logra asentarse en los patrones complejos y vuelve a la media como punto de equilibrio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatio_temporal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
